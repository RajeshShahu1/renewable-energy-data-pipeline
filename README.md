

# Renewable Energy Data Pipeline Using AWS Services

This project showcases a fully integrated, real-time energy data pipeline built using AWS services such as S3, Lambda, DynamoDB, CloudWatch, AWS CLI and SNS. It leverages Python and FastAPI to enable API-driven access and insightful visualizations, providing a robust and scalable solution for monitoring and analyzing renewable energy data.

---

## Project Overview

The objective of this project is to build a real-time data pipeline that simulates energy data from multiple renewable energy sites. The system ingests and processes data using AWS Lambda, stores it in DynamoDB, detects anomalies, and sends real-time alerts via SNS. It also includes API access for querying data and generates insightful visualizations for monitoring trends and performance.

**The project leverages the following tools and services:**

- **Python**: Simulated live data feed generation 
- **Amazon S3**:File storage and event-based trigger for ingestion
- **AWS Lambda**: Real-time processing and anomaly detection
- **DynamoDB**: Scalable NoSQL storage for processed data
- **FastAPI**: Lightweight REST API framework for querying and alerts
- **Amazon SNS**: Anomaly detection & alerts
- **Seaborn/Matplotlib**: Static data visualizations and trends 
- **Amazon CloudWatch**: Centralized logging and monitoring for Lambda
- **AWS CLI**: Infrastructure provisioning and automation (IaC)

---

## Architecture
![Architecture.png](Architecture.png)

---

## ğŸ”§ Setup Instructions

### ğŸ› ï¸ Prerequisites

* AWS Account (with admin or necessary permissions)
* AWS CLI configured
* Python 3.8 or later
* `virtualenv` installed

### Local Environment Setup

```bash
# Clone the repository
git clone https://github.com/RajeshShahu1/renewable-energy-data-pipeline.git
cd renewable-energy-data-pipeline

# Create and activate virtual environment
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows

# Install dependencies
pip install -r requirements.txt
```

### AWS Resource Setup

* **S3 Bucket** ('renewable-energy-data1') for simulated data uploads
* **DynamoDB Table** (`energy_data`)

  * Partition key: site_id(string) Unique identifier for each site
  * Sort key: timestamp(string) Time of the energy record
  * energy_generated_kwh (number) â€“ Energy generated by the site in kilowatt-hours
  * energy_consumed_kwh (number) â€“ Energy consumed by the site in kilowatt-hours
  * net_energy_kwh (number) â€“ Calculated as generated - consumed
  * anomaly (boolean) â€“ Flag to indicate anomaly 
* **SNS Topic** (`energy-anomaly-alerts`) with email subscription
* **IAM Role** with permissions: S3, DynamoDB, SNS, Lambda, CloudWatch
* **CloudWatch Logs** (automatically integrated with Lambda)

---

## How to Run Components

### Simulated Data Feed

Continuously uploads JSON files with energy data to S3.

```bash
python main.py
```

### Lambda Function

Triggered on every S3 upload. Performs:

* Parsing and validation
* Anomaly detection 
* Storing processed records in DynamoDB
* Sending alert via SNS (if anomaly found)

### Run FastAPI Backend

```bash
uvicorn dynamodb_api_fastapi:app --reload
```

Access docs:

```
http://localhost:8000/docs
```

---

## ğŸ“Š How to Visualize Data

Run the visualization script:

```bash
python visualize.py
```

Generates the following charts:

* Energy Generated vs Consumed (line chart)
* Net Energy Distribution (box plot)
* Anomaly Rate (%) per site
* Total kWh per site (stacked bar)
* Anomalies per site (bar)
* Timeline of anomalies (scatter)

All graphs are saved in the `/outputs` directory.

---

## ğŸŒ How to Use the API

### `/records`

Fetch records by site and optional time range.

```
GET /records?site_id=SolarFarm_AZ_001&start_time=2025-06-06T00:00:00&end_time=2025-06-06T23:59:59
```

### `/anomalies`

Fetch anomalies for a specific site.

```
GET /anomalies?site_id=BatteryBank_TX_005
```

## ğŸ› ï¸ Design Decisions

* **S3 â†’ Lambda â†’ DynamoDB**: Serverless and scalable data ingestion pattern.
* **SNS for alerts**: Enables real-time anomaly notification (email/SMS).
* **FastAPI**: Lightweight, fast API framework with built-in Swagger UI.
* **CloudWatch**: Logs every Lambda execution and captures errors.
* **DynamoDB**: Low-latency NoSQL storage for high-throughput access.
* **Seaborn/Matplotlib**: Easy and polished static chart generation.

---

## ğŸ“‚ Folder Structure

```
energy-data-pipeline/
â”‚
â”œâ”€â”€ simulate_feed.py              # S3 uploader for simulated data
â”œâ”€â”€ lambda_function.py            # AWS Lambda processing logic
â”œâ”€â”€ dynamodb_api_fastapi.py       # FastAPI app for data querying & alerts
â”œâ”€â”€ visualize.py                  # Visualization script
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ outputs/                      # Saved PNG charts
```

---



## ğŸ“½ï¸ Demo Video (to be added)

ğŸ“ Link to your video demonstration of the project
ğŸ§¾ Walkthrough of key features, decisions, and usage instructions

---

## ğŸ“¬ Contact

Created by **\[Your Name]**
ğŸ“§ Email: [your.email@example.com](mailto:your.email@example.com)
ğŸ”— [LinkedIn](https://linkedin.com/in/your-profile)

---


