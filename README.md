

# Renewable Energy Data Pipeline Using AWS Services

This project showcases a fully integrated, real-time energy data pipeline built using AWS services such as S3, Lambda, DynamoDB, CloudWatch, AWS CLI and SNS. It leverages Python and FastAPI to enable API-driven access and insightful visualizations, providing a robust and scalable solution for monitoring and analyzing renewable energy data.

---

## Project Overview

The objective of this project is to build a real-time data pipeline that simulates energy data from multiple renewable energy sites. The system ingests and processes data using AWS Lambda, stores it in DynamoDB, detects anomalies, and sends real-time alerts via SNS. It also includes API access for querying data and generates insightful visualizations for monitoring trends and performance.

**The project leverages the following tools and services:**

- **Python**: Simulated live data feed generation 
- **Amazon S3**:File storage and event-based trigger for ingestion
- **AWS Lambda**: Real-time processing and anomaly detection
- **DynamoDB**: Scalable NoSQL storage for processed data
- **FastAPI**: Lightweight REST API framework for querying and alerts
- **Amazon SNS**: Anomaly detection & alerts
- **Seaborn/Matplotlib**: Static data visualizations and trends 
- **Amazon CloudWatch**: Centralized logging and monitoring for Lambda
- **AWS CLI**: Infrastructure provisioning and automation (IaC)

---

## Architecture
![Architecture.png](Architecture.png)

---

## Setup Instructions

### Prerequisites

* AWS Account (with admin or necessary permissions)
* AWS CLI configured
```bash
   aws configure
```
* Python 3.8 or later
* `virtualenv` installed

### Infrastructure Deployment (AWS CLI)

From the infrastructure/ folder, run:
```bash
   infrastructure_setup.sh
```
Ensure the following files are in this folder:

* trust-policy.json
* s3_event.json
* lambda_function.py

### Local Environment Setup

```bash
# Clone the repository
git clone https://github.com/RajeshShahu1/renewable-energy-data-pipeline.git
cd renewable-energy-data-pipeline

# Create and activate virtual environment
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows

# Install dependencies
pip install -r requirements.txt
```

### AWS Resource Setup

* **S3 Bucket** ('renewable-energy-data1') for simulated data uploads
* **DynamoDB Table** (`energy_data`)

  * Partition key: site_id(string) Unique identifier for each site
  * Sort key: timestamp(string) Time of the energy record
  * energy_generated_kwh (number) â€“ Energy generated by the site in kilowatt-hours
  * energy_consumed_kwh (number) â€“ Energy consumed by the site in kilowatt-hours
  * net_energy_kwh (number) â€“ Calculated as generated - consumed
  * anomaly (boolean) â€“ Flag to indicate anomaly 
* **SNS Topic** (`energy-anomaly-alerts`) with email subscription
* **IAM Role** with permissions: S3, DynamoDB, SNS, Lambda, CloudWatch
* **CloudWatch Logs** (automatically integrated with Lambda)

---

## How to Run Components

### Simulated Data Feed

Continuously uploads JSON files with energy data to S3.

```bash
python simulated_data_feed.py
```

### Lambda Function

Triggered on every S3 upload. Performs:

* Parsing and validation
* Anomaly detection 
* Storing processed records in DynamoDB
* Sending alert via SNS (if anomaly found)

### Run FastAPI Backend

```bash
uvicorn dynamodb_api_fastapi:app --reload
```

Access Swagger docs at:

```
http://localhost:8000/docs
```
### How to Use the API

### `/records`

Fetch records by site and optional time range.

```
GET /records?site_id=SolarFarm_AZ_001&start_time=2025-06-06T00:00:00&end_time=2025-06-06T23:59:59
```
### `/anomalies`

Fetch anomalies for a specific site.

```
GET /anomalies?site_id=BatteryBank_TX_005
```
---

## How to Visualize Data

Run the visualization script:

```bash
python visualization.py
```
---
## Design Decisions

* **S3 â†’ Lambda â†’ DynamoDB**: Serverless and scalable data ingestion pattern.
* **SNS for alerts**: Enables real-time anomaly notification (email/SMS).
* **FastAPI**: Lightweight, fast API framework with built-in Swagger UI.
* **CloudWatch**: Logs every Lambda execution and captures errors.
* **DynamoDB**: Low-latency NoSQL storage for high-throughput access.
* **Seaborn/Matplotlib**: Easy and polished static chart generation.

---

## Demo Video (to be added)

ðŸ“Ž Link to your video demonstration of the project
ðŸ§¾ Walkthrough of key features, decisions, and usage instructions

---

## Contact

Created by **\[Rajesh Shahu]**
ðŸ“§ Email: [rajshahu4446@gmail.com](mailto:rajshahu4446@gmail.com)
ðŸ”— [LinkedIn](https://linkedin.com/in/rajeshshahu)

---


